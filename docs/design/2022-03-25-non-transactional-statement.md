# Non-transactional statements

- Author(s): [Ziqian Qin](http://github.com/ekexium)
- Tracking issue: https://github.com/pingcap/tidb/issues/33485

## Table of Contents

* [Introduction](#introduction)
* [Motivation or Background](#motivation-or-background)
* [Detailed Design](#detailed-design)
* [Test Design](#test-design)
    * [Functional Tests](#functional-tests)
    * [Scenario Tests](#scenario-tests)
    * [Compatibility Tests](#compatibility-tests)
    * [Benchmark Tests](#benchmark-tests)
* [Impacts & Risks](#impacts--risks)
* [Investigation & Alternatives](#investigation--alternatives)
* [Unresolved Questions](#unresolved-questions)

## Introduction

A new syntax that transforms a given DML into a serial execution of mutually exclusive collectively exhaustive statements. 

For example, `split on a limit 1000 delete from t` can be transformed into `delete from t where a between 1 and 1000` and `delete from t where a between 1001 and 2000`, assuming the min and max of `a` are respectively 1 and 2000.

## Motivation or Background

Users need to do a bulk delete or update using a single statement, while currently TiDB cannot satisfy the requirement because of the performance issue, transaction size limit, and compatibility issues with tools.

A new syntax is proposed to work around the problem. A non-transactional DML contains a DML and information that are used to "split" the statement, thus it is equivalent to a sequence of DMLs which is not transactional since it does not provide atomicity and probably isolation.

Different from the deprecated batch-DML, a non-transactional DML splits SQLs so every split SQL is a normal statement and does not risk data-index consistency.

## Detailed Design

### Syntax

The syntax: `split on <column_name> limit <batch_size> <DML>`

In the first step only `delete` is going to be supported, but `update` and `insert into select` are also worth considering.

The split column must be indexed. There are no other constraints on the DML.

There can be dry run syntax to show the actual SQLs that will be executed. Query plans are not returned since there is no elegant way to contain both a SQL and a plan in a result set. 
- `split on <column_name> limit <batch_size> dry run query <DML>` outputs the `SELECT` statement that will be executed.
- `split on <column_name> limit <batch_size> dry run <DML>` outputs how the statement will be split.

### Session

Different from most of the statements, the non-transactional DML is handled at the session level. 

Non-transactional statements are treated as `SimplePlan`s and we won't compile them. In `runStmt`, instead of `s.Exec` for most plans, `handleNontransactionalDML` will be called. In `handleNontransactionalDML`, we will split the DML into multiple statements and execute them one by one using `Session.ExecuteStatement`.

### How the split work

To find the split keys, a `select` is used to read the split column specified by the user. For example, for `split on a limit 1000 delete from t where b < 1000`, the select statement would look like: `select a from t where b < 1000 order by a`.
The result set could be large, but we don't need all of them, so result chunks are batched until the size of the batch is greater than or equal to the specified `batchSize`. Only the first and last elements of each batch are kept, thus forming a job. A job specifies a range in the specified column.

Theoretically, jobs can be executed in parallel, but that would require multiple sessions to execute them. There are two kinds of sessions in TiDB: user sessions that must be bound to client connections in a 1-on-1 manner, and internal sessions. Both kinds of sessions are inappropriate for the split statements, so in favor of maintenance, only the current user session will be used to execute the jobs, which is serial. In this way, the main benefit of a non-transactional DML is to overcome the transaction size limit, instead of performance superiority.

Each split statement is generated by embedding the split range in the where clause of the given DML using a between operator.
For example, the original statement is `split on a limit 1000 delete from t where b < 1000`, a job `{start:1, end:1000}` generates a split SQL `from t where (a between 1 and 1000) and b < 1000`.

### Error handling

A non-transactional statement obviously cannot roll back, so when one of the split statements fails, it just collects the error and continue on the job until all jobs are finished. At last, a set of errors (if there are) are returned to the user. Users may decide how to deal with these errors.

If the statement is aborted by the user, it should report its progress and return the errors it has collected.

There is one exception, however. If the first job failed, we abort the whole process and return the error. There are 2 reasons for this behavior:

1. If for any reason all of the jobs cannot succeed, failing in the first place is the best choice. For example, privileges are missing.
2. It's equivalent to rolling back the whole statement.

## Test Design

### Functional Tests

- non-transactional delete can delete everything it should delete, and don't delete anything it should not
    - multiple split column types: int, varchar(with or without new collation), timestamp, double, decimal
    - different delete statements:
        - syntax: `delete from t`, `delete t from`
        - table aliases
        - column alias
        - where clause: no `where`, simple `where`, complex `where` that contains `select`
- errors are correctly propagated
    - inject error in the first job, it should return
    - inject errors in non-initial jobs, all errors should be collected and returned, remaining jobs should finish.
    - if appropriate privilege is not granted, the statement should fail

The tests can be done in both deterministic unit tests, and randomly generated tests that use the same set of data and check the results of a simple delete and that of a non-transactional delete.

### Scenario Tests

Simulate a simple bulk delete scenario.

- There are a large amount of data that cannot be deleted using a single delete
- Users dry run and check the query plan before executing the command
- The user aborted the command and can retry the remaining part based on the information in the error (or log).
- The result should be equivalent to a single delete statement if no error has happened.

### Compatibility Tests

No need.

### Benchmark Tests

Benchmark the delete performance compared with a single normal delete statement:
1. split on a unique index
2. split on _tidb_rowid or an int PK
3. split on a clustered index

## Impacts & Risks

If any feature that influences sort and ordering (e.g. collation) is unstable, then the split process may be wrong and the delete statement may miss some rows or delete too many rows.

## Investigation & Alternatives

CockroachDB doesn't provide a similar mechanism, instead they have an official doc teaching users how to write scripts to manually split SQLs.

An alternative solution is to improve the ability of large transactions. But tools like CDC don't support large transactions well, so it's not feasible for now.

## Unresolved Questions

The user interface, including the syntax, the error messages, and the dry run results, may be improved.